{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f757742-b4e2-42fd-839c-7c2084bd9809",
   "metadata": {},
   "source": [
    "The goal of this notebook is to illustrate the possibilities of the tesserae package in combination with various bioinformatics tools in identifying intertextual references in Maximus the Confessors's _Quaestiones ad Thalassium_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b0e4620c-8b69-4c1c-868f-e5b6c27152eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bson import ObjectId\n",
    "import pandas as pd\n",
    "\n",
    "from tesserae.db import TessMongoConnection\n",
    "from tesserae.db.entities import Match, Text, Token, Unit\n",
    "from tesserae.utils import TessFile\n",
    "from tesserae.tokenizers import GreekTokenizer, LatinTokenizer\n",
    "from tesserae.unitizer import Unitizer\n",
    "from tesserae.matchers.sparse_encoding import SparseMatrixSearch\n",
    "from tesserae.utils.calculations import get_text_frequencies\n",
    "\n",
    "# Set up the connection and clean up the database\n",
    "connection = TessMongoConnection('127.0.0.1', 27017, None, None, db='tesstest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d639b8d0-e695-4355-af46-15fc397a512a",
   "metadata": {},
   "source": [
    "# Reset and load texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f15088f6-65e5-4fb7-98d5-f034fb070071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 4 texts.\n",
      "ΠΡΟΣ ΘΑΛΑΣΣΙΟΝ\n",
      "New Testament\n",
      "Historia Ecclesiastica\n",
      "Metaphysics\n"
     ]
    }
   ],
   "source": [
    "connection.connection['features'].delete_many({})\n",
    "connection.connection['frequencies'].delete_many({})\n",
    "connection.connection['matches'].delete_many({})\n",
    "connection.connection['texts'].delete_many({})\n",
    "connection.connection['tokens'].delete_many({})\n",
    "connection.connection['units'].delete_many({})\n",
    "\n",
    "with open('data/maximus_comp_test.json', 'r') as f:\n",
    "    text_meta = json.load(f)\n",
    "\n",
    "texts = []\n",
    "for t in text_meta:\n",
    "    texts.append(Text.json_decode(t))\n",
    "result = connection.insert(texts)\n",
    "print('Inserted {} texts.'.format(len(result.inserted_ids)))\n",
    "\n",
    "for text in texts:\n",
    "    tessfile = TessFile(text.path, metadata=text)\n",
    "\n",
    "    tokenizer = GreekTokenizer(connection)\n",
    "    tokens, tags, features = tokenizer.tokenize(tessfile.read(), text=tessfile.metadata)    \n",
    "    result = connection.insert(features)\n",
    "    result = connection.update(features)\n",
    "\n",
    "    unitizer = Unitizer()\n",
    "    lines, phrases = unitizer.unitize(tokens, tags, tessfile.metadata)\n",
    "    result = connection.insert(lines + phrases)    \n",
    "\n",
    "    result = connection.insert(tokens)\n",
    "    \n",
    "    print(text.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fbbec8-f42d-4a96-a44e-5e1f10ca5c61",
   "metadata": {},
   "source": [
    "# Linear Algebra Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7837415f-08ad-4156-86dc-e0b7a0e9a357",
   "metadata": {},
   "source": [
    "Load frequencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c3e8e8be-336c-46c4-a41e-947353d5cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = connection.aggregate('features',[ {'$match': { 'feature': 'lemmata' }}, \n",
    "                                          { \"$project\": {\"data\": { \"$objectToArray\": \"$frequencies\" }}},\n",
    "                                          {'$unwind': '$data'},\n",
    "                                          {'$project' : {\n",
    "                                                '_id':1,\n",
    "                                                'text' : '$data.k',\n",
    "                                                'freq' : '$data.v' }}],\n",
    "                     encode=False)\n",
    "freqs = pd.DataFrame.from_dict(list(result)).pivot_table(values='freq',index=['_id'],columns=['text'],fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a6d13-0c88-4368-bbc1-b2353ec4fbb7",
   "metadata": {},
   "source": [
    "Load the labels. (lemma labels are slow -- should implement directly in mongodb query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e8cecb8a-d457-4325-a220-e85f654ea4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemma_labels=[]\n",
    "#for idx in freqs.index:\n",
    "#    lemma_labels.append(connection.find('features',_id=idx)[0].token)\n",
    "#freqs.index = lemma_labels\n",
    "\n",
    "text_labels=[]\n",
    "for t in freqs.keys():\n",
    "    text_labels.append(connection.find('texts',_id=ObjectId(t))[0].title)\n",
    "freqs.columns = text_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea754e3-6981-4706-a842-e1a895d3e9e1",
   "metadata": {},
   "source": [
    "Make projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fc1ab870-e5d4-4fc5-b955-4c5d30e8a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.lap_v2_py3 as lap_v2\n",
    "import numpy as np\n",
    "\n",
    "names = ['ΠΡΟΣ ΘΑΛΑΣΣΙΟΝ']\n",
    "\n",
    "freqs_norm = freqs.copy()\n",
    "N = np.shape(freqs)[0]\n",
    "for item in freqs:\n",
    "    freqs_norm[item] = lap_v2.rank_norm(np.asarray(freqs[item]), dist='normal',norm=N)\n",
    "\n",
    "data = freqs_norm[names]\n",
    "basis = freqs_norm.T.drop(names).T\n",
    "\n",
    "[a, A, eta] = lap_v2.lap(basis.values, data.values, full_output=True)\n",
    "\n",
    "projections = pd.DataFrame(data = a, index = basis.keys(), columns = names)\n",
    "eta = pd.DataFrame(data = eta.T, index = data.index, columns = basis.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9b8bfc44-e83c-4f03-9e4b-7e82edca6f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ΠΡΟΣ ΘΑΛΑΣΣΙΟΝ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Testament</th>\n",
       "      <td>0.253213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Historia Ecclesiastica</th>\n",
       "      <td>0.075002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metaphysics</th>\n",
       "      <td>0.197027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ΠΡΟΣ ΘΑΛΑΣΣΙΟΝ\n",
       "New Testament                 0.253213\n",
       "Historia Ecclesiastica        0.075002\n",
       "Metaphysics                   0.197027"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208bd09a-2855-4069-aead-f162f787a182",
   "metadata": {},
   "source": [
    "# Sequence Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a69dcb-2193-4454-86cd-6ee46df0b9b5",
   "metadata": {},
   "source": [
    "Get list of lemmas from unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6562a3e4-9693-4779-ac4b-51e9eb1a70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma_seq(title,**kwargs):\n",
    "    #possible kwargs: tags, index, unit_type\n",
    "    text = connection.find('texts',title = title)[0].id\n",
    "    kwargs['text'] = text\n",
    "    result = connection.aggregate('units',[{'$match': kwargs}, \n",
    "                                       {\"$project\": {\"_id\": 0, \"tokens.display\": 1, \"tokens.features.lemmata\": 1}},\n",
    "                                       {\"$unwind\": \"$tokens\"},\n",
    "                                       {\"$project\": {\"token\": '$tokens.display', \"lemma\" : { \"$arrayElemAt\" : [\"$tokens.features.lemmata\", 0]}}}],\n",
    "                                  encode=False)\n",
    "    return pd.DataFrame.from_dict(result).set_index('token').squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2b7110-0a64-4ac2-b309-b3a8fe4a5a75",
   "metadata": {},
   "source": [
    "A simple Smith-Waterman implementation, courtesy of ChatGPT. Extremely inefficient, bould be sped up significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f5892c46-3ae1-4756-af13-13a863f0a158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned Sequence 1: Πατήρ μου ἕως ἄρτι ἐργάζεται κἀγὼ ἐργάζομαι\n",
      "Aligned Sequence 2: πατήρ μου ἕως ἄρτι ἐργάζεται κἀγὼ ἐργάζομαι\n",
      "Alignment Score: 14\n"
     ]
    }
   ],
   "source": [
    "def smith_waterman(seq1_ser, seq2_ser, match=2, mismatch=-1, gap_penalty=-1, traceback = True):\n",
    "    seq1 = list(seq1_ser.values)\n",
    "    seq2 = list(seq2_ser.values)\n",
    "    idx1 = list(seq1_ser.keys())\n",
    "    idx2 = list(seq2_ser.keys())\n",
    "    \n",
    "    # Create a matrix to store the scores for each position in the sequences\n",
    "    rows, cols = len(seq1) + 1, len(seq2) + 1\n",
    "    score_matrix = [[0 for _ in range(cols)] for _ in range(rows)]\n",
    "\n",
    "    # Initialize the maximum score and its position\n",
    "    max_score = 0\n",
    "    max_i, max_j = 0, 0\n",
    "\n",
    "    # Fill in the score matrix\n",
    "    for i in range(1, rows):\n",
    "        for j in range(1, cols):\n",
    "            if seq1[i - 1] == seq2[j - 1]:\n",
    "                match_score = score_matrix[i - 1][j - 1] + match\n",
    "            else:\n",
    "                match_score = score_matrix[i - 1][j - 1] + mismatch\n",
    "\n",
    "            delete_score = score_matrix[i - 1][j] + gap_penalty\n",
    "            insert_score = score_matrix[i][j - 1] + gap_penalty\n",
    "\n",
    "            score_matrix[i][j] = max(0, match_score, delete_score, insert_score)\n",
    "\n",
    "            if score_matrix[i][j] > max_score:\n",
    "                max_score = score_matrix[i][j]\n",
    "                max_i, max_j = i, j\n",
    "\n",
    "    if traceback:\n",
    "        # Traceback to find the aligned sequences\n",
    "        aligned_seq1, aligned_seq2 = [], []\n",
    "        i, j = max_i, max_j\n",
    "    \n",
    "        while score_matrix[i][j] > 0:\n",
    "            if score_matrix[i][j] == score_matrix[i - 1][j - 1] + (match if seq1[i - 1] == seq2[j - 1] else mismatch):\n",
    "                aligned_seq1.insert(0, idx1[i - 1])\n",
    "                aligned_seq2.insert(0, idx2[j - 1])\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "            elif score_matrix[i][j] == score_matrix[i - 1][j] + gap_penalty:\n",
    "                aligned_seq1.insert(0, idx1[i - 1])\n",
    "                aligned_seq2.insert(0, \"-\")\n",
    "                i -= 1\n",
    "            else:\n",
    "                aligned_seq1.insert(0, \"-\")\n",
    "                aligned_seq2.insert(0, idx2[j - 1])\n",
    "                j -= 1\n",
    "\n",
    "        aligned_seq1 = ' '.join(aligned_seq1)\n",
    "        aligned_seq2 = ' '.join(aligned_seq2)\n",
    "        return aligned_seq1, aligned_seq2, max_score\n",
    "    else:\n",
    "        return max_score\n",
    "\n",
    "# Example usage:\n",
    "seq1 = get_lemma_seq('ΠΡΟΣ ΘΑΛΑΣΣΙΟΝ',tags='2.2',unit_type='phrase')\n",
    "seq2 = get_lemma_seq('New Testament',tags='John.5.17',unit_type='phrase')\n",
    "aligned_seq1, aligned_seq2, score = smith_waterman(seq1, seq2, match=2, mismatch=-1, gap_penalty=-1)\n",
    "print(\"Aligned Sequence 1:\", aligned_seq1)\n",
    "print(\"Aligned Sequence 2:\", aligned_seq2)\n",
    "print(\"Alignment Score:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3434b7a-ffbd-4656-a414-3e89d61aec3f",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "1. Extend get_lemma_seq function to return the lemma sequences for the entire text at once, as a list of dicts, of the form {token=['lorem','ipsum','tempus'], lemma=[1,4,2]}. Need to modify sequence alignment algorithm too, to accept the new format.\n",
    "2. improve efficiency of sequence alignment\n",
    "3. write script to search an entire text for matches (maybe start by finding all pairs that have some minimal overlap of vocabulary)\n",
    "4. return more context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98534b78-5bd6-48d1-a99f-07e4a867a679",
   "metadata": {},
   "source": [
    "# Arc Diagram and Chord Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d146526-3f3a-4257-bb6c-c21ef7ff0a24",
   "metadata": {},
   "source": [
    "Both of these can be easily constructed using networkx, based on a graph object (https://ericmjl.github.io/Network-Analysis-Made-Simple/01-introduction/03-viz/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f648e438-0280-41f2-9b7f-a4bc0a9543e4",
   "metadata": {},
   "source": [
    "I also discovered this library called \"Bokeh,\" which can make the graphs interactive: https://docs.bokeh.org/en/latest/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8283df1e-f6e7-4ba0-9534-ddb34f350b4f",
   "metadata": {},
   "source": [
    "Next steps: \n",
    "1. Use MongoDB query to get list of all tags, (or maybe title-tag pairs), to use as the nodes\n",
    "2. Use the results of the previous section to return a list of tuples of two title-tag pairs, indicating all alignments over a certain score threshold\n",
    "3. Make arc and chord plots\n",
    "4. Interactive: use Bokeh to display the alignment when you hover over an edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bde798-9187-4a82-9259-0a912c9c1838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
