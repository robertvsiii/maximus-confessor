{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f757742-b4e2-42fd-839c-7c2084bd9809",
   "metadata": {},
   "source": [
    "The goal of this notebook is to illustrate the possibilities of the tesserae package in combination with various bioinformatics tools in identifying intertextual references in Maximus the Confessors's _Quaestiones ad Thalassium_. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b0eaa8-9e5d-44c5-8221-bf36ee43a81f",
   "metadata": {},
   "source": [
    "I want to start with LAP and BLAST. But BLAST may cause difficulty, because it is impossible to render the texts in FASTA format (unless you ignore the tokenization and just run everything together -- but you still need to convert to Latin characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e4620c-8b69-4c1c-868f-e5b6c27152eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bson import ObjectId\n",
    "import pandas as pd\n",
    "\n",
    "from tesserae.db import TessMongoConnection\n",
    "from tesserae.db.entities import Match, Text, Token, Unit\n",
    "from tesserae.utils import TessFile\n",
    "from tesserae.tokenizers import GreekTokenizer, LatinTokenizer\n",
    "from tesserae.unitizer import Unitizer\n",
    "from tesserae.matchers.sparse_encoding import SparseMatrixSearch\n",
    "from tesserae.utils.calculations import get_text_frequencies\n",
    "\n",
    "# Set up the connection and clean up the database\n",
    "connection = TessMongoConnection('127.0.0.1', 27017, None, None, db='tesstest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d639b8d0-e695-4355-af46-15fc397a512a",
   "metadata": {},
   "source": [
    "# Reset and load texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f15088f6-65e5-4fb7-98d5-f034fb070071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 4 texts.\n"
     ]
    }
   ],
   "source": [
    "connection.connection['features'].delete_many({})\n",
    "connection.connection['frequencies'].delete_many({})\n",
    "connection.connection['matches'].delete_many({})\n",
    "connection.connection['texts'].delete_many({})\n",
    "connection.connection['tokens'].delete_many({})\n",
    "connection.connection['units'].delete_many({})\n",
    "\n",
    "with open('data/maximus_comp_test.json', 'r') as f:\n",
    "    text_meta = json.load(f)\n",
    "\n",
    "texts = []\n",
    "for t in text_meta:\n",
    "    texts.append(Text.json_decode(t))\n",
    "result = connection.insert(texts)\n",
    "print('Inserted {} texts.'.format(len(result.inserted_ids)))\n",
    "\n",
    "for text in texts:\n",
    "    tessfile = TessFile(text.path, metadata=text)\n",
    "    tokenizer = GreekTokenizer(connection)\n",
    "    tokens, tags, features = tokenizer.tokenize(tessfile.read(), text=tessfile.metadata)    \n",
    "    result = connection.insert(features)\n",
    "    result = connection.insert(tokens)\n",
    "\n",
    "    unitizer = Unitizer()\n",
    "    lines, phrases = unitizer.unitize(tokens, tags, tessfile.metadata)\n",
    "    result = connection.insert(lines + phrases)    \n",
    "    print(text.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fbbec8-f42d-4a96-a44e-5e1f10ca5c61",
   "metadata": {},
   "source": [
    "# Linear Algebra Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8cecb8a-d457-4325-a220-e85f654ea4ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['_id'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48828/4021529378.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'texts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfreqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_text_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfreqs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_text_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tesserae-v5/tesserae/utils/calculations.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(connection, text, feature)\u001b[0m\n\u001b[1;32m     11\u001b[0m                                             \u001b[0;34m{\u001b[0m\u001b[0;34m\"$project\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"features\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                             \u001b[0;34m{\u001b[0m\u001b[0;34m\"$unwind\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"$features.\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                             {'$group' : {\"_id\" : \"$features.\"+feature , text : {\"$sum\": 1}}}],\n\u001b[1;32m     14\u001b[0m                                   encode=False)\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mfreqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtual_env/py38/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   5855\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5856\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5859\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5862\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['_id'] are in the columns\""
     ]
    }
   ],
   "source": [
    "texts = connection.find('texts')\n",
    "freqs = pd.DataFrame(get_text_frequencies(connection,str(texts[0].id)))\n",
    "\n",
    "for text in texts[1:]:\n",
    "    freqs=freqs.join(get_text_frequencies(connection,str(text.id)),how='inner')\n",
    "freqs = freqs.fillna(value=0).astype('int64')\n",
    "\n",
    "lemma_labels=[]\n",
    "for idx in freqs.index:\n",
    "    lemma_labels.append(connection_cb.find('features',_id=idx)[0].token)\n",
    "freqs.index = lemma_labels\n",
    "\n",
    "text_labels=[]\n",
    "for t in freqs.keys():\n",
    "    text_labels.append(connection_cb.find('texts',_id=ObjectId(t))[0].title)\n",
    "freqs.columns = text_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce30d2-8aa5-436c-aaed-713bed7c7048",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ab870-e5d4-4fc5-b955-4c5d30e8a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.lap_v2_py3 as lap_v2\n",
    "import numpy as np\n",
    "\n",
    "names = ['meno']\n",
    "\n",
    "freqs_norm = freqs.copy()\n",
    "N = np.shape(freqs)[0]\n",
    "for item in freqs:\n",
    "    freqs_norm[item] = lap_v2.rank_norm(np.asarray(freqs[item]), dist='normal',norm=N)\n",
    "\n",
    "data = freqs_norm[names]\n",
    "basis = freqs_norm.T.drop(names).T\n",
    "\n",
    "[a, A, eta] = lap_v2.lap(basis.values, data.values, full_output=True)\n",
    "\n",
    "projections = pd.DataFrame(data = a, index = basis.keys(), columns = names)\n",
    "eta = pd.DataFrame(data = eta.T, index = data.index, columns = basis.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208bd09a-2855-4069-aead-f162f787a182",
   "metadata": {},
   "source": [
    "# Multiple Sequence Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc6fefb-75bb-44e7-8bbb-87e18a1175b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
